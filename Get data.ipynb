{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import requests\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.worldometers.info/coronavirus/'\n",
    "\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "r = requests.get(url, headers=header)\n",
    "\n",
    "# Read text result into Pandas\n",
    "dfs = pd.read_html(r.text)\n",
    "# Look for the first table\n",
    "df = dfs[0]\n",
    "# Fill missing values with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "df.to_csv('./Data/world_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "homepage_soup = bs.BeautifulSoup(r.text, 'lxml')\n",
    "# Using the table on the main page, only the countries with links (<a> tags) have detailed historical data.\n",
    "country_elements = homepage_soup.select('table[id=\"main_table_countries_today\"] > tbody > tr > td > a')\n",
    "# Start with an empty list\n",
    "countries_with_detailed_data = {}\n",
    "# Iterate through each element, and add the contents (country name) to a list\n",
    "for individual_element in country_elements:\n",
    "    country_name = individual_element.contents[0]\n",
    "    country_url = individual_element['href']\n",
    "    countries_with_detailed_data[country_name] = country_url\n",
    "\n",
    "print(\"Can get detailed data for %s\" % \", \".join(list(countries_with_detailed_data.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looks for script elements that contain the JS stats by day, and extract x and y axis values\n",
    "def extractDataFromGraph(soup, chart_id):\n",
    "    scripts = soup.select('script[type=\"text/javascript\"]')\n",
    "    for individual_script in scripts:\n",
    "        individual_script = individual_script.get_text(strip=True)\n",
    "        if(chart_id in individual_script):\n",
    "            x_text = re.search('categories: \\[([^\\]]+)\\]', individual_script).group(1)\n",
    "            y_text = re.search('data: \\[([0-9, ]+)]', individual_script).group(1)\n",
    "            x_values = x_text.replace('\"', '').split(\",\")\n",
    "            y_values = y_text.split(\",\")\n",
    "    return (x_values, y_values)\n",
    "\n",
    "# Iterate over each country and extract the same data, save to CSV\n",
    "def getDetailedDataForCountry(country, url_part):\n",
    "    url = 'https://www.worldometers.info/coronavirus/' + url_part\n",
    "    r = requests.get(url, headers=header).text\n",
    "    soup = bs.BeautifulSoup(r, 'lxml')\n",
    "    dates, cases = extractDataFromGraph(soup, \"coronavirus-cases-linear\")\n",
    "    cases = pd.to_numeric(cases)\n",
    "    # a bit risky ignoring dates for the following, if for some reason they are different on different graphs\n",
    "    active_cases = pd.to_numeric(extractDataFromGraph(soup, \"graph-active-cases-total\")[1])\n",
    "    try:\n",
    "        deaths = pd.to_numeric(extractDataFromGraph(soup, \"coronavirus-deaths-linear\")[1])\n",
    "    except:\n",
    "        deaths = [0]*len(cases)\n",
    "    try:\n",
    "        daily_deaths = pd.to_numeric(extractDataFromGraph(soup, \"graph-deaths-daily\")[1])\n",
    "    except:\n",
    "        daily_deaths = [0]*len(cases)\n",
    "    #daily_cases = extractDataFromGraph(soup, \"graph-cases-daily\")[1]\n",
    "    # doesn't work: graph-cases-daily\n",
    "    \n",
    "    #calculate daily cases\n",
    "    daily_cases = cases*0\n",
    "    for i in range(0,len(cases)):\n",
    "        daily_cases[i] = int(cases[i]) - int(cases[i-1])\n",
    "    daily_cases[0] = 0\n",
    "    \n",
    "    #calculate total fatality rate\n",
    "    CFR = deaths/cases\n",
    "    \n",
    "    #calculate rate of growth of cases\n",
    "    CGR = cases*0.0\n",
    "    for i in range(0,len(cases)):\n",
    "        try:\n",
    "            CGR[i] = float(cases[i]) / float(cases[i-1])\n",
    "        except:\n",
    "            CGR[i] = 0.0\n",
    "            \n",
    "    #calculate rate of growth of deaths\n",
    "    DGR = cases*0.0\n",
    "    for i in range(0,len(cases)):\n",
    "        try:\n",
    "            DGR[i] = float(deaths[i]) / float(deaths[i-1])\n",
    "        except:\n",
    "            DGR[i] = 0.0\n",
    "     \n",
    "    \n",
    "    df_country = pd.DataFrame(\n",
    "        {'Cases': cases\n",
    "    })\n",
    "    \n",
    "    df_country['Dates'] = dates\n",
    "    df_country['Cases'] = cases\n",
    "    df_country['Deaths'] = deaths\n",
    "    df_country['Daily Cases'] = daily_cases\n",
    "    \n",
    "    try:\n",
    "        df_country['Daily Deaths'] = daily_deaths\n",
    "    except: \n",
    "        len_diff = len(cases)-len(daily_deaths)\n",
    "        daily_deaths = np.pad(daily_deaths, (len_diff, 0), 'constant')\n",
    "        df_country['Daily Deaths'] = daily_deaths\n",
    "            \n",
    "    \n",
    "    df_country['CFR'] = CFR\n",
    "    df_country['Cases growth rate']: CGR\n",
    "    df_country['Deaths growth rate']: DGR\n",
    "    \n",
    "\n",
    "    df_country.fillna(0,inplace=True)\n",
    "    \n",
    "    #change daily cases from float to int (it is automatically changed to float in a np.array)\n",
    "    for i in df_country['Daily Cases']:\n",
    "        i = int(i)\n",
    "    \n",
    "    df_country = df_country.fillna(0)\n",
    "    file_name = './Data/Countries/' + country + '.csv'\n",
    "    df_country.to_csv(file_name)\n",
    "\n",
    "# Execute the functions to collect data for all countries\n",
    "for country, url in countries_with_detailed_data.items():\n",
    "    getDetailedDataForCountry(country, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From country dfs, create dfs for each stat and country over time\n",
    "def createStatDfs(countries):\n",
    "    #create empty dfs required\n",
    "    df_cases = None\n",
    "    df_cases_2 = pd.DataFrame()\n",
    "    df_deaths = None\n",
    "    df_deaths_2 = pd.DataFrame()\n",
    "    df_daily_cases = None\n",
    "    df_daily_cases_2 = pd.DataFrame()\n",
    "    df_daily_deaths = None\n",
    "    df_daily_deaths_2 = pd.DataFrame()\n",
    "    #df_active_cases = None\n",
    "    #df_active_cases_2 = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    for country in countries:\n",
    "        file_name = './Data/Countries/' + country + '.csv'\n",
    "        df = pd.read_csv(file_name)\n",
    "        \n",
    "        \n",
    "        #Cases\n",
    "        if df_cases is None:\n",
    "            df_cases = df            \n",
    "            df_cases = df_cases.set_index('Dates')\n",
    "            df_cases = df_cases[['Cases']]\n",
    "            df_cases_2[country] = df_cases['Cases']\n",
    "        else:\n",
    "            df_cases = df\n",
    "            df_cases = df_cases.set_index('Dates')\n",
    "            df_cases = df_cases[['Cases']]\n",
    "            df_cases = df_cases.rename(columns={'Cases':country})\n",
    "            df_cases_2 = pd.concat([df_cases_2, df_cases], axis=1, sort=False)\n",
    "        \n",
    "        #Deaths\n",
    "        if df_deaths is None:\n",
    "            df_deaths = df\n",
    "            df_deaths = df_deaths.set_index('Dates')\n",
    "            df_deaths = df_deaths[['Deaths']]\n",
    "            df_deaths_2[country] = df_deaths['Deaths']\n",
    "        else:\n",
    "            df_deaths = df\n",
    "            df_deaths = df_deaths.set_index('Dates')\n",
    "            df_deaths = df_deaths[['Deaths']]\n",
    "            df_deaths = df_deaths.rename(columns={'Deaths':country})\n",
    "            df_deaths_2 = pd.concat([df_deaths_2, df_deaths], axis=1, sort=False)\n",
    "\n",
    "        #Daily Cases\n",
    "        if df_daily_cases is None:\n",
    "            df_daily_cases = df\n",
    "            df_daily_cases = df_daily_cases.set_index('Dates')\n",
    "            df_daily_cases = df_daily_cases[['Daily Cases']]\n",
    "            df_daily_cases_2[country] = df_daily_cases['Daily Cases']\n",
    "        else:\n",
    "            df_daily_cases = df\n",
    "            df_daily_cases = df_daily_cases.set_index('Dates')\n",
    "            df_daily_cases = df_daily_cases[['Daily Cases']]\n",
    "            df_daily_cases = df_daily_cases.rename(columns={'Daily Cases':country})\n",
    "            df_daily_cases_2 = pd.concat([df_daily_cases_2, df_daily_cases], axis=1, sort=False)\n",
    "        \n",
    "        #Daily Deaths\n",
    "        if df_daily_deaths is None:\n",
    "            df_daily_deaths = df\n",
    "            df_daily_deaths = df_daily_deaths.set_index('Dates')\n",
    "            df_daily_deaths = df_daily_deaths[['Daily Deaths']]\n",
    "            df_daily_deaths_2[country] = df_daily_deaths['Daily Deaths']\n",
    "        else:\n",
    "            df_daily_deaths = df\n",
    "            df_daily_deaths = df_daily_deaths.set_index('Dates')\n",
    "            df_daily_deaths = df_daily_deaths[['Daily Deaths']]\n",
    "            df_daily_deaths = df_daily_deaths.rename(columns={'Daily Deaths':country})\n",
    "            df_daily_deaths_2 = pd.concat([df_daily_deaths_2, df_daily_deaths], axis=1, sort=False)\n",
    "        \n",
    "\n",
    "            \n",
    "    df_cases_2.fillna(0, inplace=True)\n",
    "    df_cases_2 = df_cases_2.astype(int)\n",
    "\n",
    "    df_deaths_2.fillna(0, inplace=True)\n",
    "    df_deaths_2 = df_deaths_2.astype(int)\n",
    "    \n",
    "    df_daily_cases_2.fillna(0, inplace=True)\n",
    "    df_daily_cases_2 = df_daily_cases_2.astype(int)\n",
    "    \n",
    "    df_daily_deaths_2.fillna(0, inplace=True)\n",
    "    df_daily_deaths_2 = df_daily_deaths_2.astype(int)\n",
    "    \n",
    "    df_cases_2.to_csv('./Data/Stats/Cases.csv')\n",
    "    df_deaths_2.to_csv('./Data/Stats/Deaths.csv')\n",
    "    df_daily_cases_2.to_csv('./Data/Stats/Daily cases.csv')\n",
    "    df_daily_deaths_2.to_csv('./Data/Stats/Daily deaths.csv')\n",
    "    #df_active_cases_2.to_csv('./Data/Stats/Active cases.csv')\n",
    "    \n",
    "    \n",
    "#Create list of countries\n",
    "countries = []\n",
    "for country, url in countries_with_detailed_data.items():\n",
    "    if country == 'China':                        #brings China to front of list\n",
    "        countries.insert(0, country)\n",
    "    else: \n",
    "        countries.append(country)\n",
    "\n",
    "createStatDfs(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create datasets used for animations (one long dataframe with all countries)\n",
    "df = pd.read_csv('./Data/world_info.csv')\n",
    "\n",
    "path = './Data/Countries'\n",
    "onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "t = pd.date_range(start='1/1/2020', end=date.today().strftime(\"%m/%d/%Y\"))\n",
    "dt = pd.DataFrame(np.arange(0,len(t), 1), index=t, columns=['Day0'])\n",
    "\n",
    "countries = []\n",
    "for c in onlyfiles:\n",
    "    df = pd.read_csv(path+'/'+c)\n",
    "    df['Dates'] = df['Dates'].astype(str) + ' 2020'\n",
    "    df['Dates'] = pd.to_datetime(df['Dates'],format='%b %d %Y')\n",
    "    df.set_index(df['Dates'],inplace=True)\n",
    "    df = df.merge(dt,how='right',left_index=True, right_index=True,copy=False)\n",
    "    df.fillna(0,inplace=True)\n",
    "    df['Country'] = str.split(c,'.')[0]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df = df[['Day0','Country','Dates','Cases','Deaths','Daily Cases','Daily Deaths','CFR']]\n",
    "    df['New Cases Last Week'] = df['Cases'].diff(periods=7)\n",
    "    df['New Deaths Last Week'] = df['Deaths'].diff(periods=7)\n",
    "    df['New Cases'] = df['Cases'].diff()\n",
    "    df['New Deaths'] = df['Deaths'].diff()\n",
    "    df['CFR_Current']=df['New Deaths'].rolling(window=28).sum()/df['New Cases'].shift(13).rolling(window=28).sum()\n",
    "    df['CFR_Total']=df['Deaths']/df['Cases']\n",
    "    df.fillna(0,inplace=True)\n",
    "    countries.append(df)\n",
    "\n",
    "df = pd.concat(countries)\n",
    "df = df.sort_values(by='Day0')\n",
    "df.reset_index(inplace=True,drop=True)        \n",
    "\n",
    "df.to_csv('./Data/timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
